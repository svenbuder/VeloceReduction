{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from veloce_luminosa_reduction.utils import identify_calibration_and_science_runs, match_month_to_date, read_veloce_fits_image_and_metadata\n",
    "from veloce_luminosa_reduction.reduction import substract_overscan\n",
    "from veloce_luminosa_reduction import config\n",
    "# from veloce_luminosa_reduction.coadding import co_add_spectra\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Master Calibration Frames\n",
    "# master_bias = median_combine(bias_frames)\n",
    "# bias_subtracted_darks = [dark - master_bias for dark in dark_frames]\n",
    "# master_dark = median_combine(bias_subtracted_darks)\n",
    "# bias_subtracted_flats = [flat - master_bias for flat in flatfield_frames]\n",
    "# master_flat = median_combine(bias_subtracted_flats)\n",
    "# master_flat /= np.median(master_flat)\n",
    "\n",
    "# # Apply Master Calibration Frames\n",
    "# bias_subtracted_science = science_frame - master_bias\n",
    "# dark_scale_factor = science_exposure_time / dark_exposure_time\n",
    "# scaled_master_dark = master_dark * dark_scale_factor\n",
    "# dark_subtracted_science = bias_subtracted_science - scaled_master_dark\n",
    "# flat_corrected_science = dark_subtracted_science / master_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ceef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_objects(date, object_name, calibration_runs, science_runs):\n",
    "    \n",
    "    # Create master calibration frames (flat, bias, dark, etc.)\n",
    "#     master_frames = create_master_frames(fits_data['calibration'])\n",
    "    \n",
    "    if object_name == \"all\":\n",
    "        object_names  = list(science_runs.keys())\n",
    "    else:\n",
    "        object_names = [object_name]\n",
    "    \n",
    "    for object_name in object_names:\n",
    "\n",
    "        print('\\nNow reducing '+object_name)\n",
    "        \n",
    "        # Loop over runs\n",
    "        print(science_runs[object_name][1:])\n",
    "        for run in science_runs[object_name][1:]:\n",
    "\n",
    "            if config.debug:\n",
    "                f, gs = plt.subplots(1,3,figsize=(12,5))\n",
    "            \n",
    "            # Loop over CCDs\n",
    "            for ccd in [1,2,3]:\n",
    "            \n",
    "                full_image, metadata = read_veloce_fits_image_and_metadata(config.raw_data_dir+'/'+date+'/ccd_'+str(ccd)+'/'+date[-2:]+match_month_to_date(date)+str(ccd)+run+'.fits')\n",
    "\n",
    "                trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "\n",
    "                if config.debug:\n",
    "\n",
    "                    ax = gs[ccd-1]\n",
    "                    ax.set_title(object_name+' CCD'+str(ccd))\n",
    "                    count_percentiles = np.percentile(trimmed_image, q=[20,95])\n",
    "                    s = ax.imshow(trimmed_image,cmap='OrRd',vmin=np.max([0,count_percentiles[0]]),vmax=count_percentiles[-1])\n",
    "                    cbar = plt.colorbar(s, ax=ax, extend='both', orientation='horizontal')\n",
    "                    cbar.set_label('Counts')\n",
    "                    \n",
    "            if config.debug:\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "    \n",
    "#     # Read in FITS files based on the extracted paths\n",
    "#     fits_data = read_fits_files(files_to_process)\n",
    "\n",
    "#     # Reduce science observations using calibration frames\n",
    "#     reduced_data = reduce_data(fits_data['science'], master_frames)\n",
    "\n",
    "#     # Calibrate the wavelength of the reduced observations\n",
    "#     calibrated_data = calibrate_wavelengths(reduced_data)\n",
    "    \n",
    "#     # Normalize the spectrum\n",
    "#     normalized_orders = normalize_spectrum(calibrated_data)\n",
    "    \n",
    "#     # Patch the orders to one spectrum\n",
    "#     normalized_merged_spectrum = merge_order(normalized_orders)\n",
    "\n",
    "#     # Output the final reduced and calibrated data\n",
    "#     save_final_spectrum(normalized_merged_spectrum, args.night, args.object)\n",
    "\n",
    "#     # TO BE ADDED WHEN WORKING WITH MULTIPLE OBSERVATIONS!\n",
    "#     # Coadding of spectra\n",
    "#     normalised_coadded_spectrum = co_add_spectra(spectra, common_wavelength)\n",
    "\n",
    "        print('\\nReduction of '+object_name+' complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    main_directory = os.getcwd()\n",
    "    \n",
    "    # Get all necessary information through parser (otherwise assume we are debugging in jupyter)\n",
    "    try:\n",
    "        parser = argparse.ArgumentParser(description='Reduce CCD images from the Veloce echelle spectrograph.', add_help=True)\n",
    "        parser.add_argument('date', default='240219', type=str, help='Observation night in YYMMDD format.')\n",
    "        parser.add_argument('object_name', default='HIP71683', type=str, help='Name of the science object.')\n",
    "        parser.add_argument('-in', '--raw_data_dir', default=main_directory+'../raw_data', type=str, help='Directory of raw data as created by Veloce YYMMDD/ccd_1 etc.')\n",
    "        parser.add_argument('-out', '--reduced_data_dir', default=main_directory+'../reduced_data', type=str, help='Directory of raw data as created by Veloce YYMMDD/ccd_1 etc.')\n",
    "        parser.add_argument('--debug', action='store_true')\n",
    "        args = parser.parse_args()\n",
    "        config.date = args.date\n",
    "        config.object_name = args.object_name\n",
    "        config.raw_data_dir = args.raw_data_dir\n",
    "        config.reduced_data_dir = args.reduced_data_dir\n",
    "        config.debug = args.debug\n",
    "    except:\n",
    "        config.date = '240219'\n",
    "        config.object_name = 'HIP71683'\n",
    "        config.raw_data_dir = '/Users/buder/git/veloce_luminosa_reduction/raw_data'\n",
    "        config.reduced_data_dir = '/Users/buder/git/veloce_luminosa_reduction/reduced_data'\n",
    "        config.debug = True\n",
    "    \n",
    "    if config.debug:\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Extract relevant information from night log\n",
    "    calibration_runs, science_runs = identify_calibration_and_science_runs(config.date, config.raw_data_dir)\n",
    "    \n",
    "    # Process all frames of a given object_name\n",
    "    process_objects(config.date, config.object_name, calibration_runs, science_runs)\n",
    "    \n",
    "    print(f\"\\nReduction and calibration succesfull and complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a0fca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828ddb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ce162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
