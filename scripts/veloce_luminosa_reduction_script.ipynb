{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54038f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from veloce_luminosa_reduction import config\n",
    "from veloce_luminosa_reduction.utils import identify_calibration_and_science_runs, match_month_to_date, read_veloce_fits_image_and_metadata, polynomial_function, radial_velocity_shift\n",
    "from veloce_luminosa_reduction.reduction import substract_overscan, extract_initial_order_ranges_and_coeffs\n",
    "from veloce_luminosa_reduction.calibration import get_wavelength_coeffs_from_vdarc\n",
    "# from veloce_luminosa_reduction.order_merging import interpolate_orders_and_merge\n",
    "# from veloce_luminosa_reduction.post_processing import degrade_resolution_with_uncertainty\n",
    "# from veloce_luminosa_reduction.coadding import co_add_spectra\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "import astropy.units as u\n",
    "SSO = EarthLocation.of_site('Siding Spring Observatory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_order_ranges, initial_order_coeffs = extract_initial_order_ranges_and_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_coeffs = get_wavelength_coeffs_from_vdarc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e14c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_objects(date, object_name, master_flats, science_runs):\n",
    "    \n",
    "    # Create master calibration frames (flat, bias, dark, etc.)\n",
    "#     master_frames = create_master_frames(fits_data['calibration'])\n",
    "    \n",
    "    if object_name == \"all\":\n",
    "        object_names  = list(science_runs.keys())\n",
    "    else:\n",
    "        object_names = [object_name]\n",
    "    \n",
    "    for object_name in object_names:\n",
    "\n",
    "        print('\\nNow reducing '+object_name)\n",
    "        \n",
    "        # Loop over runs\n",
    "        print(science_runs[object_name][1:])\n",
    "        for run in science_runs[object_name][1:]:\n",
    "\n",
    "#             if config.debug:\n",
    "#                 f, gs = plt.subplots(3,3,figsize=(12,12))\n",
    "            \n",
    "            # Loop over CCDs\n",
    "            for ccd in [1,2,3]:\n",
    "            \n",
    "                full_image, metadata = read_veloce_fits_image_and_metadata(config.working_directory+'raw_data/'+date+'/ccd_'+str(ccd)+'/'+date[-2:]+match_month_to_date(date)+str(ccd)+run+'.fits')\n",
    "\n",
    "                object_coordinates = SkyCoord(ra = metadata['MEANRA'], dec = metadata['MEANDEC'], frame=\"icrs\", unit=\"deg\")\n",
    "                vbary_corr_kms = object_coordinates.radial_velocity_correction( \n",
    "                    kind='barycentric', \n",
    "                    obstime = Time(val=metadata['UTMJD'],format='mjd', scale='utc'),\n",
    "                    location=SSO\n",
    "                ).to(u.km/u.s).value\n",
    "\n",
    "                # Overscan Subtraction\n",
    "                trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "\n",
    "                # Flat Field Correction\n",
    "                flat_corrected_image = np.array(trimmed_image, dtype=float) / np.array(master_flats['ccd_'+str(ccd)], dtype=float)\n",
    "                \n",
    "#                 if config.debug:\n",
    "\n",
    "#                     ax = gs[0,ccd-1]\n",
    "#                     ax.set_title(object_name+' CCD'+str(ccd))\n",
    "#                     count_percentiles = np.percentile(trimmed_image, q=[20,95])\n",
    "#                     s = ax.imshow(trimmed_image,cmap='OrRd',vmin=np.max([0,count_percentiles[0]]),vmax=count_percentiles[-1])\n",
    "#                     cbar = plt.colorbar(s, ax=ax, extend='both', orientation='horizontal')\n",
    "#                     cbar.set_label('Counts')\n",
    "                    \n",
    "#                     ax = gs[1,ccd-1]\n",
    "#                     ax.set_title(object_name+' CCD'+str(ccd))\n",
    "#                     count_percentiles = np.percentile(master_flats['ccd_'+str(ccd)], q=[20,95])\n",
    "#                     s = ax.imshow(master_flats['ccd_'+str(ccd)],cmap='OrRd',vmin=np.max([0,count_percentiles[0]]),vmax=count_percentiles[-1])\n",
    "#                     cbar = plt.colorbar(s, ax=ax, extend='both', orientation='horizontal')\n",
    "#                     cbar.set_label('Counts')\n",
    "\n",
    "#                     ax = gs[2,ccd-1]\n",
    "#                     ax.set_title(object_name+' CCD'+str(ccd))\n",
    "#                     count_percentiles = np.percentile(flat_corrected_image, q=[20,95])\n",
    "#                     s = ax.imshow(flat_corrected_image,cmap='OrRd',vmin=np.max([0,count_percentiles[0]]),vmax=count_percentiles[-1])\n",
    "#                     cbar = plt.colorbar(s, ax=ax, extend='both', orientation='horizontal')\n",
    "#                     cbar.set_label('Counts')\n",
    "\n",
    "#             if config.debug:\n",
    "#                 plt.tight_layout()\n",
    "#                 plt.show()\n",
    "#                 plt.close()\n",
    "\n",
    "                # Extract orders\n",
    "                counts_in_orders = dict()\n",
    "                for order in initial_order_coeffs:\n",
    "                    if order[4] == str(ccd):\n",
    "                    \n",
    "                        order_xrange_begin = np.array(polynomial_function(initial_order_ranges[order],*initial_order_coeffs[order])-45,dtype=int)\n",
    "                        order_xrange_end   = np.array(polynomial_function(initial_order_ranges[order],*initial_order_coeffs[order]),dtype=int)\n",
    "\n",
    "                        order_counts = []\n",
    "                        for x_index, x in enumerate(initial_order_ranges[order]):\n",
    "                            order_counts.append(np.sum(flat_corrected_image[x,order_xrange_begin[x_index]:order_xrange_end[x_index]],axis=0))\n",
    "                        counts_in_orders[order] = np.array(order_counts)\n",
    "\n",
    "                # Calibrate Wavelengths\n",
    "                raw_wavelengths_per_order = dict()\n",
    "                vbary_corr_wavelengths_per_order = dict()\n",
    "                for order in wavelength_coeffs.keys():\n",
    "                    if order[4] == str(ccd):\n",
    "                        if order[4] == '1':\n",
    "                            wavelength_reference_pixels = 2170\n",
    "                        if order[4] == '2':\n",
    "                            wavelength_reference_pixels = 2170\n",
    "                        if order[4] == '3':\n",
    "                            wavelength_reference_pixels = 2473\n",
    "\n",
    "                        # important for telluric correction\n",
    "                        raw_wavelengths_per_order[order] = 10. * polynomial_function(np.arange(len(counts_in_orders[order]))-wavelength_reference_pixels,*wavelength_coeffs[order])\n",
    "\n",
    "                        # important to achieve rest-wavelengths\n",
    "                        vbary_corr_wavelengths_per_order[order] = radial_velocity_shift(\n",
    "                            vbary_corr_kms,\n",
    "                            raw_wavelengths_per_order[order]\n",
    "                        )\n",
    "                        \n",
    "                        plt.figure(figsize=(15,3))\n",
    "                        plt.title(order)\n",
    "                        plt.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            counts_in_orders[order]\n",
    "                        )\n",
    "                        plt.show()\n",
    "                        plt.close\n",
    "\n",
    "    \n",
    "#     # Normalize the spectrum\n",
    "#     normalized_orders = normalize_spectrum(calibrated_data)\n",
    "    \n",
    "#     # Patch the orders to one spectrum\n",
    "#     normalized_merged_spectrum = interpolate_and_merge(wavelengths, fluxes, uncertainties, linear_wavelengths)\n",
    "\n",
    "#     # Output the final reduced and calibrated data\n",
    "#     save_final_spectrum(normalized_merged_spectrum, args.night, args.object)\n",
    "\n",
    "#     # TO BE ADDED WHEN WORKING WITH MULTIPLE OBSERVATIONS!\n",
    "#     # Coadding of spectra\n",
    "#     normalised_coadded_spectrum = co_add_spectra(normalized_merged_spectrum, common_wavelength)\n",
    "\n",
    "#     # Degrade spectrum down to 4MOST HR\n",
    "#     spectrum_4most_hr = degrade_resolution_with_uncertainty(wavelength, flux, flux_uncertainty, 80000, 22000)\n",
    "\n",
    "\n",
    "        print('\\nReduction of '+object_name+' complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    main_directory = os.getcwd()\n",
    "    \n",
    "    # Get all necessary information through parser (otherwise assume we are debugging in jupyter)\n",
    "    try:\n",
    "        parser = argparse.ArgumentParser(description='Reduce CCD images from the Veloce echelle spectrograph.', add_help=True)\n",
    "        parser.add_argument('date', default='240219', type=str, help='Observation night in YYMMDD format.')\n",
    "        parser.add_argument('object_name', default='HIP71683', type=str, help='Name of the science object.')\n",
    "        parser.add_argument('-wd', '--working_directory', default=os.getcwd(), type=str, help='Directory of raw/reduced data as created by Veloce YYMMDD/ccd_1 etc.')\n",
    "        parser.add_argument('--debug', action='store_true')\n",
    "        args = parser.parse_args()\n",
    "        config.date = args.date\n",
    "        config.object_name = args.object_name\n",
    "        config.working_directory = args.working_directory\n",
    "        config.reduced_data_dir = args.reduced_data_dir\n",
    "        config.debug = args.debug\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if config.debug:\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Extract relevant information from night log\n",
    "    calibration_runs, science_runs = identify_calibration_and_science_runs(config.date, config.working_directory+'raw_data/')\n",
    "    \n",
    "    # Master Flat\n",
    "    master_flats = dict()\n",
    "    for ccd in [1,2,3]:\n",
    "        master_flats['ccd_'+str(ccd)] = []\n",
    "        if ccd == 1: flat_runs = calibration_runs['Flat_60.0'][:7]\n",
    "        if ccd == 2: flat_runs = calibration_runs['Flat_1.0'][:7]\n",
    "        if ccd == 3: flat_runs = calibration_runs['Flat_0.1'][:7]\n",
    "        # Read in, overscan subtract and append images to array\n",
    "        for run in flat_runs:\n",
    "            full_image, metadata = read_veloce_fits_image_and_metadata(config.working_directory+'raw_data/'+config.date+'/ccd_'+str(ccd)+'/'+config.date[-2:]+match_month_to_date(config.date)+str(ccd)+run+'.fits')\n",
    "            trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "            master_flats['ccd_'+str(ccd)].append(trimmed_image)\n",
    "        # Normalise across runs.\n",
    "        master_flats['ccd_'+str(ccd)] = np.array(np.median(master_flats['ccd_'+str(ccd)],axis=0),dtype=float)\n",
    "        # Normalise to Median\n",
    "        overall_median = np.nanmedian(master_flats['ccd_'+str(ccd)])\n",
    "        # Ensure that values 0.0 or below are getting the normalising factor 1\n",
    "        master_flats['ccd_'+str(ccd)][master_flats['ccd_'+str(ccd)] <= 0.0] = overall_median\n",
    "        master_flats['ccd_'+str(ccd)] /= overall_median\n",
    "        \n",
    "#     if config.debug:\n",
    "#         f, gs = plt.subplots(1,3,figsize=(12,3))\n",
    "#         for ccd in [1,2,3]:    \n",
    "#             ax = gs[ccd-1]\n",
    "#             ax.set_title('Master Flat CCD'+str(ccd))\n",
    "#             count_percentiles = np.percentile(master_flats['ccd_'+str(ccd)], q=[0,100])\n",
    "#             s = ax.imshow(master_flats['ccd_'+str(ccd)],cmap='OrRd',vmin=np.max([0,count_percentiles[0]]),vmax=count_percentiles[-1])\n",
    "#             cbar = plt.colorbar(s, ax=ax, extend='both', orientation='horizontal')\n",
    "#             cbar.set_label('Counts')\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "    \n",
    "    # Process all frames of a given object_name\n",
    "    process_objects(config.date, config.object_name, master_flats, science_runs)\n",
    "\n",
    "    print(f\"\\nReduction and calibration succesfull and complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a0fca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
