{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b56ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from veloce_luminosa_reduction import config\n",
    "\n",
    "from veloce_luminosa_reduction.plotting import plot_ccd_imshow, create_rainbow_colormap, create_transparent_greyscale_colormap\n",
    "from veloce_luminosa_reduction.utils import identify_calibration_and_science_runs, match_month_to_date, read_veloce_fits_image_and_metadata, polynomial_function, radial_velocity_shift, interpolate_spectrum\n",
    "from veloce_luminosa_reduction.reduction import substract_overscan, extract_initial_order_ranges_and_coeffs\n",
    "from veloce_luminosa_reduction.calibration import get_wavelength_coeffs_from_vdarc\n",
    "from veloce_luminosa_reduction.korg_synthesis import calculate_synthetic_korg_spectrum\n",
    "from veloce_luminosa_reduction.post_processing import degrade_resolution_with_uncertainty, interpolate_orders_and_merge, coadd_spectra\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.polynomial.chebyshev import Chebyshev\n",
    "from scipy.signal import medfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "import astropy.units as u\n",
    "SSO = EarthLocation.of_site('Siding Spring Observatory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation for Veloce Luminosa\n",
    "gbs_values = Table.read('../veloce_luminosa_reduction/literature_data/gbs_v3_and_v2.1_joined.fits')\n",
    "\n",
    "# Telluric (as well as solar and arcturus) reference spectrum\n",
    "# with dispersion of 0.0045 Å/px @3726.7Å to 0.0112 Å/px @9300.0Å\n",
    "solar_arcturus_telluric_atlas = Table.read('../veloce_luminosa_reduction/literature_data/hinkle_2000_atlas_2000vnia.book..../solar_arcturus_telluric_atlas.fits')\n",
    "solar_arcturus_telluric_atlas['TELLURIC'][solar_arcturus_telluric_atlas['TELLURIC'] <= 0.01] = 0.01\n",
    "solar_arcturus_telluric_atlas['telluric_r80000'], dummy = degrade_resolution_with_uncertainty(\n",
    "    solar_arcturus_telluric_atlas['WAVELENGTH'],\n",
    "    solar_arcturus_telluric_atlas['TELLURIC'], \n",
    "    flux_uncertainty = 0.001 * np.ones(len(solar_arcturus_telluric_atlas['TELLURIC'])),\n",
    "    original_resolution = 150000.,\n",
    "    target_resolution = 80000.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_objects(date, object_name, master_flats, science_runs):\n",
    "    \"\"\"\n",
    "    The function that runs through all observations for science_runs matches object_name.\n",
    "    object_name can also be \"all\" in which case the function will run through all science_runs.keys()\n",
    "    \n",
    "    The function follows the following workflow:\n",
    "    1) Create a synthetic Korg spectrum (if config.teff/logg/fe_h given or there is a match with the gbs_values)\n",
    "    2) Read in FITS file for each CCD, subtract overscan, flat-field correct, estimate barycentric velocity\n",
    "    3) Extract Orders from 2D image to 1D\n",
    "    4) Calibrate Wavelength px->Å\n",
    "    5) Normalise Orders with synthetic Korg spectrum\n",
    "    ...\n",
    "    N) Produce a rainbow plot\n",
    "\n",
    "    INPUT:\n",
    "    - date (str): The observation date in YYMMDD format.\n",
    "    - object_name (str): The name of the target object matching keys in `science_runs`; use \"all\" to process data for all available objects.\n",
    "    - master_flats (dict): A dictionary with Master Flat fields, keyed by 'ccd_X' for each CCD X, where X is in the range [1,2,3].\n",
    "    - science_runs (dict): A dictionary where each key is associated with an array of run identifiers (e.g., [RRRR, RRRR, ...]).\n",
    "    \"\"\"\n",
    "    if object_name == \"all\":\n",
    "        object_names  = list(science_runs.keys())\n",
    "    else:\n",
    "        object_names = [object_name]\n",
    "        \n",
    "    # Initial wavelenght solutions by C. Tinney are optimised for specific reference pixels\n",
    "    initial_order_ranges, initial_order_coeffs = extract_initial_order_ranges_and_coeffs()\n",
    "    initial_wavelength_coeffs = get_wavelength_coeffs_from_vdarc()\n",
    "    # Below we adjust the initial values to be even better before we would fit\n",
    "    initial_order_references_pixels = dict()\n",
    "    for order in initial_wavelength_coeffs.keys():\n",
    "        if order[4] == '1':\n",
    "            initial_order_references_pixels[order] = 2130\n",
    "            if int(order[-3:]) >= 153:\n",
    "                initial_order_references_pixels[order] = 2500\n",
    "            if int(order[-3:]) >= 160:\n",
    "                initial_order_references_pixels[order] = 2420\n",
    "        if order[4] == '2':\n",
    "            initial_order_references_pixels[order] = 2385\n",
    "        if order[4] == '3':\n",
    "            initial_order_references_pixels[order] = 2435\n",
    "\n",
    "    for object_name in object_names:\n",
    "        \n",
    "        print('\\nNow reducing '+object_name)\n",
    "        print('    Available runs: ',science_runs[object_name])\n",
    "        \n",
    "        # Check if we have the necessary stellar parameters for a Korg synthesis\n",
    "        # parsed as arguments or in the GBS reference list\n",
    "        if config.teff is not None:\n",
    "            teff = config.teff\n",
    "            logg = config.logg\n",
    "            fe_h = config.fe_h\n",
    "            \n",
    "            print('\\n    Using parsed Teff/logg/[Fe/H] for '+object_name+': Teff='+str(teff)+', logg='+str(logg)+', [Fe/H]='+str(fe_h))\n",
    "\n",
    "        elif object_name in gbs_values['hip']:\n",
    "            object_name_match_in_gbs = np.where(object_name == gbs_values['hip'])[0][0]\n",
    "            teff = gbs_values['teff'][object_name_match_in_gbs]\n",
    "            logg = gbs_values['logg'][object_name_match_in_gbs]\n",
    "            fe_h = gbs_values['fe_h'][object_name_match_in_gbs]\n",
    "            \n",
    "            print('\\n    Found matching Teff/logg/[Fe/H] for '+object_name+' in GBS: Teff='+str(teff)+', logg='+str(logg)+', [Fe/H]='+str(fe_h))\n",
    "            print('    Calculating Korg spectrum from 3900-9500Å')\n",
    "            time_start = time.time()\n",
    "            korg_synthesis, korg_wavelength_vac, korg_wavelength_air, korg_flux = calculate_synthetic_korg_spectrum(teff, logg, fe_h)\n",
    "            print('    Calculated Korg spectrum in '+\"{:.1f}\".format(time.time() - time_start)+'s')\n",
    "            \n",
    "            # Interpolate the telluric spectrum onto the Korg wavelength grid.\n",
    "            # Note: Telluric is air, so we are using the Korg air\n",
    "            telluric_on_korg_wavelength = interpolate_spectrum(\n",
    "                solar_arcturus_telluric_atlas['WAVELENGTH'],\n",
    "                solar_arcturus_telluric_atlas['telluric_r80000'].clip(min=0.1),\n",
    "                korg_wavelength_air\n",
    "            )\n",
    "\n",
    "            if object_name == 'HIP71683':\n",
    "                radial_velocity = -24.7\n",
    "                # shift Korg onto observed wavelength scale!\n",
    "                korg_wavelength_vac = radial_velocity_shift(-radial_velocity, korg_wavelength_vac)\n",
    "            if object_name == 'HIP76976':\n",
    "                radial_velocity = -170.1\n",
    "                # shift Korg onto observed wavelength scale!\n",
    "                korg_wavelength_vac = radial_velocity_shift(-radial_velocity, korg_wavelength_vac)\n",
    "            \n",
    "        else:\n",
    "            # safety mechanism in case Korg available, but no stellar parameters\n",
    "            config.use_korg = False\n",
    "            teff = None; logg = None; fe_h = None\n",
    "            print('    No Teff/logg/[Fe/H] available. Not using Korg synthesis to normalise spectra')\n",
    "            \n",
    "        ########################################\n",
    "        # Loop over runs\n",
    "        for run in science_runs[object_name][1:]:\n",
    "            \n",
    "            ########################################\n",
    "            # Flat Field Correction\n",
    "            print('    Reading FITS for run '+str(run)+' and correcting with flat field')\n",
    "            flat_corrected_image = dict()\n",
    "\n",
    "            if config.debug:\n",
    "                f, gs = plt.subplots(1,3,figsize=(12,3.5))\n",
    "            \n",
    "            for ccd in [1,2,3]:\n",
    "            \n",
    "                # Read in Science Image\n",
    "                full_image, metadata = read_veloce_fits_image_and_metadata(config.working_directory+'raw_data/'+date+'/ccd_'+str(ccd)+'/'+date[-2:]+match_month_to_date(date)+str(ccd)+run+'.fits')\n",
    "                \n",
    "                # Overscan Subtraction\n",
    "                trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "\n",
    "                # Flat Field Correction\n",
    "                flat_corrected_image['ccd_'+str(ccd)] = np.array(trimmed_image, dtype=float) / np.array(master_flats['ccd_'+str(ccd)], dtype=float)\n",
    "                \n",
    "                # Plot Flat Field Corrected Image\n",
    "                if config.debug:\n",
    "                    plot_ccd_imshow(ax=gs[ccd-1], image = flat_corrected_image['ccd_'+str(ccd)], panel_title = object_name+' ('+str(run)+') CCD'+str(ccd)+' FF-corrected')\n",
    "            if config.debug:\n",
    "                plt.tight_layout()\n",
    "                Path(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)).mkdir(parents=True, exist_ok=True)\n",
    "                plt.savefig(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)+'/'+config.date+'_'+str(run)+'_oscantrimmed_ffcorrected.pdf',dpi=200,bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "            ########################################\n",
    "            # Estimate Barycentric Velocity Correction\n",
    "            object_coordinates = SkyCoord(ra = metadata['MEANRA'], dec = metadata['MEANDEC'], frame=\"icrs\", unit=\"deg\")\n",
    "            vbary_corr_kms = object_coordinates.radial_velocity_correction( \n",
    "                kind='barycentric', \n",
    "                obstime = Time(val=metadata['UTMJD'],format='mjd', scale='utc'),\n",
    "                location=SSO\n",
    "            ).to(u.km/u.s).value\n",
    "\n",
    "            ########################################\n",
    "            print('    Extracting Orders')\n",
    "            # Extract Orders (2D -> 1D spectra)\n",
    "            counts_in_orders = dict()\n",
    "            for order in initial_order_coeffs:\n",
    "                ccd = order[4]\n",
    "                # initial_order_ranges[order] are the initial orders reported by C.Tinney.\n",
    "                # # Let's use the full range of the trimmed image\n",
    "                order_xrange_begin = np.array(polynomial_function(np.arange(np.shape(flat_corrected_image['ccd_'+str(ccd)])[0]),*initial_order_coeffs[order])-45,dtype=int)\n",
    "                order_xrange_end   = np.array(polynomial_function(np.arange(np.shape(flat_corrected_image['ccd_'+str(ccd)])[0]),*initial_order_coeffs[order]),dtype=int)\n",
    "                order_counts = []\n",
    "                for x_index, x in enumerate(initial_order_ranges[order]):\n",
    "                    order_counts.append(np.sum(flat_corrected_image['ccd_'+str(ccd)][x,order_xrange_begin[x_index]:order_xrange_end[x_index]],axis=0))\n",
    "                counts_in_orders[order] = np.array(order_counts)\n",
    "                        \n",
    "            ########################################\n",
    "            # Calibrate Order Wavelengths\n",
    "            print('    Calibration Order Wavelengths')\n",
    "            raw_wavelengths_per_order = dict()\n",
    "            vbary_corr_wavelengths_per_order = dict()\n",
    "            \n",
    "            for order in initial_wavelength_coeffs.keys():\n",
    "                \n",
    "                # Important for telluric correction\n",
    "                # Note: coefficients above are reported for nm-scale, not Å-scale!\n",
    "                raw_wavelengths_per_order[order] = 10. * polynomial_function(np.arange(len(counts_in_orders[order]))-initial_order_references_pixels[order],*initial_wavelength_coeffs[order])\n",
    "\n",
    "                # Apply barycentric velocity correction\n",
    "                vbary_corr_wavelengths_per_order[order] = radial_velocity_shift(\n",
    "                    vbary_corr_kms,\n",
    "                    raw_wavelengths_per_order[order]\n",
    "                )\n",
    "\n",
    "            ########################################\n",
    "            # Normalise Orders\n",
    "            print('    Normalising Orders')\n",
    "            flux_in_orders = dict()\n",
    "            korg_flux_in_orders = dict()\n",
    "            korg_flux_with_tellurics_in_orders = dict()\n",
    "            for order in initial_wavelength_coeffs.keys():\n",
    "                # 1) If we use Korg\n",
    "                if config.use_korg:\n",
    "                    korg_flux_in_orders[order] = np.array(interpolate_spectrum(\n",
    "                        korg_wavelength_vac,\n",
    "                        korg_flux,\n",
    "                        vbary_corr_wavelengths_per_order[order]\n",
    "                    ))\n",
    "\n",
    "                    # Shift telluric lines by -vbary_corr and the interpolate on vbary_corrected grid\n",
    "                    telluric_flux_in_order = np.array(interpolate_spectrum(\n",
    "                        radial_velocity_shift(\n",
    "                            -vbary_corr_kms,\n",
    "                            korg_wavelength_vac\n",
    "                        ),\n",
    "                        telluric_on_korg_wavelength,\n",
    "                        vbary_corr_wavelengths_per_order[order]\n",
    "                    ))\n",
    "                    # Now multiply korg flux and the telluric spectrum that was shifted by -vbary_corr\n",
    "                    korg_flux_with_tellurics_in_orders[order] = korg_flux_in_orders[order] * telluric_flux_in_order\n",
    "\n",
    "                    flux_ratio = counts_in_orders[order] / korg_flux_in_orders[order]\n",
    "\n",
    "                    # Identify absorption peaks above Xth percentile and also neglect first and last Y pixels for fitting\n",
    "                    outlier_percentile = 10\n",
    "                    edge_cut = 100\n",
    "                    outlier_percentiles = np.percentile(flux_ratio,q=[outlier_percentile,100-outlier_percentile])\n",
    "                    absorption_pixels = flux_ratio > outlier_percentiles[1]\n",
    "                    absorption_pixels[flux_ratio < outlier_percentiles[0]] = True\n",
    "                    absorption_pixels[:edge_cut] = True\n",
    "                    absorption_pixels[-edge_cut:] = True\n",
    "\n",
    "                    filter_kernel_size = 101\n",
    "                    smooth_flux_ratio = medfilt(flux_ratio[~absorption_pixels], kernel_size=filter_kernel_size)\n",
    "\n",
    "                    chebychev_degree = 5\n",
    "                    chebychev_fit = Chebyshev.fit(vbary_corr_wavelengths_per_order[order][~absorption_pixels], smooth_flux_ratio, deg=chebychev_degree)\n",
    "\n",
    "                    flux_in_orders[order] = counts_in_orders[order] / chebychev_fit(vbary_corr_wavelengths_per_order[order])\n",
    "\n",
    "                    if config.debug:\n",
    "                        f, gs = plt.subplots(2,1,figsize=(15,6),sharex=True)\n",
    "                        \n",
    "                        ax = gs[0]\n",
    "                        ax.set_title(config.date+' '+str(run)+' '+str(object_name)+' CCD'+order[4]+' Order '+order.split('_')[-1]+' ('+str(initial_order_ranges[order][0])+','+str(initial_order_ranges[order][-1])+') Ref: '+str(initial_order_references_pixels[order]))\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            flux_ratio,\n",
    "                            label = 'Flux Ratio'\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order][~absorption_pixels],\n",
    "                            flux_ratio[~absorption_pixels],\n",
    "                            label = 'Flux Ratio (w/o top/bottom '+str(outlier_percentile)+'th perc & '+str(edge_cut)+' px edge cut)'\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order][~absorption_pixels],\n",
    "                            smooth_flux_ratio,\n",
    "                            label = 'Smoothed Flux Ratio (Kernel Size: '+str(filter_kernel_size)+')'\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            chebychev_fit(vbary_corr_wavelengths_per_order[order]),\n",
    "                            label = 'Chebychev Fit to Smooth Ratio ('+str(chebychev_degree)+' degrees)'\n",
    "                        )\n",
    "                        ax.legend(ncol=4)\n",
    "\n",
    "                        ax = gs[1]\n",
    "                        ax.set_title(config.date+' '+str(run)+' '+str(object_name)+' CCD'+order[4]+' Order '+order.split('_')[-1]+' ('+str(initial_order_ranges[order][0])+','+str(initial_order_ranges[order][-1])+') Ref: '+str(initial_order_references_pixels[order]))\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            flux_in_orders[order],\n",
    "                            label = 'Veloce', c = 'k', lw=1\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            korg_flux_in_orders[order],\n",
    "                            label = 'Korg', c='C0', lw=1\n",
    "                        )\n",
    "                        ax.plot(\n",
    "                            vbary_corr_wavelengths_per_order[order],\n",
    "                            korg_flux_with_tellurics_in_orders[order],\n",
    "                            label = 'Korg w/ tellurics', c='C4', lw=1\n",
    "                        )\n",
    "                        ax.legend(ncol=3)\n",
    "                        ax.set_xlabel(r'Wavelength (vacuum) / $\\mathrm{\\AA}$')\n",
    "                        ax.set_ylabel(r'Flux / norm.')\n",
    "                        ax_upper = ax.twiny()\n",
    "                        wavelength_indices = np.linspace(100,len(vbary_corr_wavelengths_per_order[order])-100,5,dtype=int)\n",
    "                        ax_upper.set_xticks(\n",
    "                            wavelength_indices/(1.0*len(vbary_corr_wavelengths_per_order[order])),\n",
    "                            wavelength_indices\n",
    "                        )\n",
    "                        ax.set_ylim(0.0,1.2)\n",
    "                        plt.tight_layout()\n",
    "                        Path(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)).mkdir(parents=True, exist_ok=True)\n",
    "                        plt.savefig(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)+'/'+config.date+'_'+str(run)+'_'+order+'_normed_flux.pdf',dpi=200,bbox_inches='tight')\n",
    "                        plt.close()\n",
    "\n",
    "#     # Patch the orders to one spectrum\n",
    "#     normalized_merged_spectrum = interpolate_and_merge(wavelengths, fluxes, uncertainties, linear_wavelengths)\n",
    "\n",
    "#     # Output the final reduced and calibrated data\n",
    "#     save_final_spectrum(normalized_merged_spectrum, args.night, args.object)\n",
    "\n",
    "#     # TO BE ADDED WHEN WORKING WITH MULTIPLE OBSERVATIONS!\n",
    "#     # Coadding of spectra\n",
    "#     normalised_coadded_spectrum = co_add_spectra(normalized_merged_spectrum, common_wavelength)\n",
    "\n",
    "#     # Degrade spectrum down to 4MOST HR\n",
    "#     spectrum_4most_hr = degrade_resolution_with_uncertainty(wavelength, flux, flux_uncertainty, 80000, 22000)\n",
    "\n",
    "        ########################################\n",
    "        # Produce some beautiful outreach material\n",
    "        print('    Producing Rainbow Plot')        \n",
    "        matrix_color = []\n",
    "        matrix_wavelength = []\n",
    "        for ccd in [1,2,3]:\n",
    "            # We have to go in reverse order, as increasing order means decreasing wavelength\n",
    "            for order in list(flux_in_orders.keys())[::-1]:\n",
    "                if order[4] == str(ccd):\n",
    "                    if not (\n",
    "                        ((ccd == 1) & (int(order.split('_')[-1]) in [138,139,140,154,155,156,157,158,159,160,161,162,163,164,165,166,167])) |\n",
    "                        ((ccd == 2) & (int(order.split('_')[-1]) in [103])) |\n",
    "                        ((ccd == 3) & (int(order.split('_')[-1]) in [65,104]))\n",
    "                    ):\n",
    "\n",
    "                        # better signal and less overlap\n",
    "                        pixel_cutoff = 500\n",
    "\n",
    "                        # color array of \n",
    "                        wavelength_array = np.linspace(vbary_corr_wavelengths_per_order[order][0],vbary_corr_wavelengths_per_order[order][-1],4094 - 2*pixel_cutoff)\n",
    "                        colorrange_array = np.linspace(0,len(flux_in_orders[order][pixel_cutoff:-pixel_cutoff]),4094 - 2*pixel_cutoff)\n",
    "\n",
    "                        flux_interpolate = interpolate_spectrum(\n",
    "                            np.arange(len(flux_in_orders[order][pixel_cutoff:-pixel_cutoff])),\n",
    "                            flux_in_orders[order][pixel_cutoff:-pixel_cutoff],\n",
    "                            colorrange_array\n",
    "                        )\n",
    "                        for i in range(10):\n",
    "                            matrix_color.append(flux_interpolate)\n",
    "                            matrix_wavelength.append(wavelength_array)\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        shape = np.shape(matrix_color)\n",
    "        aspect = shape[1]/shape[0]\n",
    "        s = plt.imshow(matrix_wavelength, aspect = aspect, vmin = 3750, vmax = 7800, cmap = create_rainbow_colormap())\n",
    "        s = plt.imshow(matrix_color, aspect = aspect, vmin = 0.5, vmax = 1, cmap = create_transparent_greyscale_colormap())\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.tight_layout()\n",
    "        Path(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)).mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)+'/'+config.date+'_'+str(run)+'_'+object_name+'_rainbow.pdf',dpi=200,bbox_inches='tight')\n",
    "        plt.savefig(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+str(run)+'/'+config.date+'_'+str(run)+'_'+object_name+'_rainbow.png',dpi=200,bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print('\\nReduction of '+object_name+' complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    main_directory = os.getcwd()\n",
    "    \n",
    "    # Get all necessary information through parser (otherwise assume we are debugging in jupyter)\n",
    "    try:\n",
    "        parser = argparse.ArgumentParser(description='Reduce CCD images from the Veloce echelle spectrograph.', add_help=True)\n",
    "        parser.add_argument('date', default='240219', type=str, help='Observation night in YYMMDD format.')\n",
    "        parser.add_argument('object_name', default='HIP71683', type=str, help='Name of the science object.')\n",
    "        parser.add_argument('-wd', '--working_directory', default=os.getcwd(), type=str, help='Directory of raw/reduced data as created by Veloce YYMMDD/ccd_1 etc.')\n",
    "        parser.add_argument('-teff', default=None, type=float, help='Effective temperature to calculate Korg spectra')\n",
    "        parser.add_argument('-logg', default=None, type=float, help='Surface gravity to calculate Korg spectra')\n",
    "        parser.add_argument('-fe_h', default=None, type=float, help='Iron abundance to calculate Korg spectra')\n",
    "        parser.add_argument('--debug', action='store_true')\n",
    "        args = parser.parse_args()\n",
    "        if len(args.date) == 6:\n",
    "            config.date = args.date\n",
    "        else:\n",
    "            raise ValueError('date must be a 6 digit string in the format YYMMDD')\n",
    "        config.object_name = args.object_name\n",
    "        config.working_directory = args.working_directory\n",
    "        config.debug = args.debug\n",
    "        \n",
    "        if args.teff is not None:\n",
    "            try:\n",
    "                config.teff = float(args.teff)\n",
    "            except:\n",
    "                raise ValueError('teff argument must be float')\n",
    "            try:\n",
    "                config.logg = float(args.logg)\n",
    "            except:\n",
    "                raise ValueError('logg argument must be float')\n",
    "            try:\n",
    "                config.fe_h = float(args.fe_h)\n",
    "            except:\n",
    "                raise ValueError('fe_h argument must be float')\n",
    "        try:\n",
    "            from juliacall import Main as jl\n",
    "            config.use_korg = True\n",
    "        except:\n",
    "            print('Could not import juliacall. Will not use Korg to normalise spectra.')\n",
    "            config.use_korg = False\n",
    "    except:\n",
    "        config.teff = None\n",
    "        config.logg = None\n",
    "        config.fe_h = None\n",
    "        pass\n",
    "    \n",
    "    if config.debug:\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Extract relevant information from night log\n",
    "    calibration_runs, science_runs = identify_calibration_and_science_runs(config.date, config.working_directory+'raw_data/')\n",
    "    \n",
    "    # Overwrite GBS stars that were also observed as part of the Halo program\n",
    "    if 'Halo11' in science_runs.keys():\n",
    "        science_runs['HIP76976'] = science_runs['Halo11']\n",
    "        if config.object_name == 'Halo11':\n",
    "            print('\\nRewriting GBS object_name to HIP identifier (rather than HaloX)')\n",
    "            config.object_name = 'HIP76976'\n",
    "    \n",
    "    # Create Master Flat\n",
    "    master_flats = dict()\n",
    "    for ccd in [1,2,3]:\n",
    "        master_flats['ccd_'+str(ccd)] = []\n",
    "        if ccd == 1: flat_runs = calibration_runs['Flat_60.0'][:1]\n",
    "        if ccd == 2: flat_runs = calibration_runs['Flat_1.0'][:1]\n",
    "        if ccd == 3: flat_runs = calibration_runs['Flat_0.1'][:1]\n",
    "        # Read in, overscan subtract and append images to array\n",
    "        for run in flat_runs:\n",
    "            full_image, metadata = read_veloce_fits_image_and_metadata(config.working_directory+'raw_data/'+config.date+'/ccd_'+str(ccd)+'/'+config.date[-2:]+match_month_to_date(config.date)+str(ccd)+run+'.fits')\n",
    "            trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "            master_flats['ccd_'+str(ccd)].append(trimmed_image)\n",
    "        # Normalise across runs.\n",
    "        master_flats['ccd_'+str(ccd)] = np.array(np.median(master_flats['ccd_'+str(ccd)],axis=0),dtype=float)\n",
    "        # Normalise to Median\n",
    "        overall_median = np.nanmedian(master_flats['ccd_'+str(ccd)])\n",
    "        # Ensure that values 0.0 or below are getting the normalising factor 1\n",
    "        master_flats['ccd_'+str(ccd)][master_flats['ccd_'+str(ccd)] <= 0.0] = overall_median\n",
    "        master_flats['ccd_'+str(ccd)] /= overall_median\n",
    "\n",
    "    # if debug: save master flat\n",
    "    if config.debug:\n",
    "        f, gs = plt.subplots(1,3,figsize=(12,4))\n",
    "        for ccd in [1,2,3]:\n",
    "            plot_ccd_imshow(ax = gs[ccd-1], image = master_flats['ccd_'+str(ccd)], panel_title = 'Master Flat CCD'+str(ccd))\n",
    "        plt.tight_layout()\n",
    "        Path(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/').mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(config.working_directory+'reduced_data/'+config.date+'/diagnostic_plots/'+config.date+'_master_flat.pdf',dpi=200,bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Process all frames of a given object_name\n",
    "    process_objects(config.date, config.object_name, master_flats, science_runs)\n",
    "\n",
    "    print(f\"\\nReduction and calibration succesfull and complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a0fca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4291f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
