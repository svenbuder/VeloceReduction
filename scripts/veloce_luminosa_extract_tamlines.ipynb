{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f9eda9",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b56ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from veloce_luminosa_reduction import config\n",
    "\n",
    "from veloce_luminosa_reduction.plotting import plot_ccd_imshow, create_rainbow_colormap, create_transparent_greyscale_colormap\n",
    "from veloce_luminosa_reduction.utils import identify_calibration_and_science_runs, match_month_to_date, read_veloce_fits_image_and_metadata, polynomial_function, radial_velocity_shift, interpolate_spectrum\n",
    "from veloce_luminosa_reduction.reduction import substract_overscan, extract_initial_order_ranges_and_coeffs\n",
    "from veloce_luminosa_reduction.calibration import get_wavelength_coeffs_from_vdarc\n",
    "from veloce_luminosa_reduction.korg_synthesis import calculate_synthetic_korg_spectrum\n",
    "from veloce_luminosa_reduction.post_processing import degrade_resolution_with_uncertainty, interpolate_orders_and_merge, coadd_spectra\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.polynomial.chebyshev import Chebyshev\n",
    "from scipy.signal import medfilt, find_peaks\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "import astropy.units as u\n",
    "SSO = EarthLocation.of_site('Siding Spring Observatory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bb2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.date = '240219'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3973caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "\n",
      "Identifying calibration and science runs now\n",
      "\n",
      "More than 1 Log file present, continuing with /Users/buder/git/veloce_luminosa_reduction/raw_data//240219/240219-AAT-2023B-24.log\n",
      "\n",
      "Warning for HIP71683 (run 0140): Rosso slightly saturated.\n",
      "Warning for HIP71683 (run 0140): Rosso slightly saturated.\n",
      "Warning for HIP71683 (run 0140): Rosso slightly saturated.\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant information from night log\n",
    "calibration_runs, science_runs = identify_calibration_and_science_runs(config.date, config.working_directory+'raw_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3930bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tramlines\n",
    "initial_order_ranges, initial_order_coeffs = extract_initial_order_ranges_and_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e6ab04",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Master Flat\n",
      "Extracting Master ThXe\n",
      "Extracting Master LC\n",
      "Extracting HIP37664\n",
      "Extracting HIP47431\n",
      "Extracting HIP50887\n",
      "Extracting HIP56127\n",
      "Extracting HIP56343\n",
      "Failed to extract HIP56343\n",
      "Extracting HIP57757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File may have been truncated: actual file length (11967934) is smaller than the expected size (35300160) [astropy.io.fits.file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting HIP63608\n",
      "Extracting HIP65721\n",
      "Extracting HIP67459\n",
      "Extracting HIP71681\n",
      "Extracting HIP71683\n",
      "Extracting HIP73184\n",
      "Extracting HIP74975\n",
      "Extracting HIP69673\n"
     ]
    }
   ],
   "source": [
    "def extract_orders(ccd1_runs, ccd2_runs, ccd3_runs, Flat = False, LC = False, Science = False, tramline_debug = False):\n",
    "    \n",
    "    # Extract Images from CCDs 1-3\n",
    "    images = dict()\n",
    "    \n",
    "    # Read in, overscan subtract and append images to array\n",
    "    for ccd in [1,2,3]:\n",
    "        \n",
    "        images['ccd_'+str(ccd)] = []\n",
    "        if ccd == 1: runs = ccd1_runs\n",
    "        if ccd == 2: runs = ccd2_runs\n",
    "        if ccd == 3: runs = ccd3_runs\n",
    "        \n",
    "        for run in runs:\n",
    "            full_image, metadata = read_veloce_fits_image_and_metadata(config.working_directory+'raw_data/'+config.date+'/ccd_'+str(ccd)+'/'+config.date[-2:]+match_month_to_date(config.date)+str(ccd)+run+'.fits')\n",
    "            trimmed_image, os_median, os_rms = substract_overscan(full_image, metadata)\n",
    "            images['ccd_'+str(ccd)].append(trimmed_image)\n",
    "        \n",
    "        # For science: sum counts\n",
    "        if Science:\n",
    "            images['ccd_'+str(ccd)] = np.array(np.median(images['ccd_'+str(ccd)],axis=0),dtype=float)\n",
    "        # For calibration: calculate median\n",
    "        else:\n",
    "            images['ccd_'+str(ccd)] = np.array(np.median(images['ccd_'+str(ccd)],axis=0),dtype=float)\n",
    "\n",
    "        if Flat:\n",
    "            images['ccd_'+str(ccd)] /= np.nanmax(images['ccd_'+str(ccd)])\n",
    "\n",
    "    counts_in_orders = []\n",
    "    noise_in_orders = []\n",
    "    \n",
    "    if tramline_debug:\n",
    "        plt.figure(figsize=(15,15))\n",
    "        s = plt.imshow(images['ccd_2'], vmin = 1, vmax = 20, cmap='Greys',aspect=5)\n",
    "        plt.colorbar(s)\n",
    "    \n",
    "    for order in initial_order_coeffs:\n",
    "        ccd = order[4]\n",
    "\n",
    "        # Identify the tramline ranges for each order\n",
    "        # initial_order_ranges[order] are the initial orders reported by C.Tinney.\n",
    "        left = -45\n",
    "        right = 0\n",
    "        if LC & (ccd == '3'):\n",
    "            left = 0\n",
    "            right = 10\n",
    "        if LC & (ccd == '2'):\n",
    "            left = 8\n",
    "            right = 20\n",
    "        order_xrange_begin = np.array(polynomial_function(np.arange(np.shape(images['ccd_'+str(ccd)])[0]),*initial_order_coeffs[order])+left,dtype=int)\n",
    "        order_xrange_end   = np.array(polynomial_function(np.arange(np.shape(images['ccd_'+str(ccd)])[0]),*initial_order_coeffs[order])+right,dtype=int)\n",
    "\n",
    "        if tramline_debug:\n",
    "            if ccd == '2':\n",
    "                plt.plot(order_xrange_begin,np.arange(len(order_xrange_begin)),c='C0',lw=0.5)\n",
    "                plt.plot(order_xrange_end,np.arange(len(order_xrange_begin)),c='C1',lw=0.5)\n",
    "        \n",
    "        # Save the flux from each tramlines in a row; give NaN values to regions without flux\n",
    "        order_counts = np.zeros(np.shape(images['ccd_'+str(ccd)])[1]); order_counts[:] = np.nan\n",
    "        order_noise = np.zeros(np.shape(images['ccd_'+str(ccd)])[1]); order_noise[:] = np.nan\n",
    "        for x_index, x in enumerate(initial_order_ranges[order]):\n",
    "            \n",
    "            counts_in_pixels_to_be_summed = images['ccd_'+str(ccd)][x,order_xrange_begin[x_index]:order_xrange_end[x_index]]\n",
    "            \n",
    "            order_counts[initial_order_ranges[order][0] + x_index] = np.sum(counts_in_pixels_to_be_summed,axis=0)\n",
    "            \n",
    "            # We are making the quick assumption that the read noise is simply the maximum overscan RMS\n",
    "            read_noise = np.max([os_rms[region] for region in os_rms.keys()])*np.sqrt(len(counts_in_pixels_to_be_summed))\n",
    "\n",
    "            # For science: multiply read noise with nr of runs,\n",
    "            # since we are coadding frames, rather than using median\n",
    "            if Science:\n",
    "                read_noise*np.sqrt(len(runs))\n",
    "\n",
    "            if tramline_debug & Science & (x_index == 2000):\n",
    "                print(order)\n",
    "                print('x_index:      ',2000)\n",
    "                print('sum(counts):  ',np.sum(counts_in_pixels_to_be_summed,axis=0))\n",
    "                print('sqrt(counts): ',np.sqrt(np.sum(counts_in_pixels_to_be_summed,axis=0)))\n",
    "                print('read noise:   ',read_noise)\n",
    "                print('counts:       ',counts_in_pixels_to_be_summed)\n",
    "                plt.figure()\n",
    "                plt.title(order)\n",
    "                plt.plot(counts_in_pixels_to_be_summed)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                \n",
    "            # noise = sqrt(flux) + read_noise * nr of pixels * nr of runs/exposures\n",
    "            order_noise[initial_order_ranges[order][0] + x_index] = np.sqrt(np.sum(counts_in_pixels_to_be_summed,axis=0)) + read_noise\n",
    "\n",
    "        counts_in_orders.append(order_counts)\n",
    "        noise_in_orders.append(order_noise)\n",
    "\n",
    "    if tramline_debug:\n",
    "        plt.xlim(2500,4200)\n",
    "        plt.ylim(2000,2500)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return(np.array(counts_in_orders),np.array(noise_in_orders))\n",
    "\n",
    "# Extract Master Flat\n",
    "print('Extracting Master Flat')\n",
    "master_flat, noise = extract_orders(\n",
    "    ccd1_runs = calibration_runs['Flat_60.0'][:1],\n",
    "    ccd2_runs = calibration_runs['Flat_1.0'][:1],\n",
    "    ccd3_runs = calibration_runs['Flat_0.1'][:1],\n",
    "    Flat = True\n",
    ")\n",
    "\n",
    "# Extract Master ThXe\n",
    "print('Extracting Master ThXe')\n",
    "master_thxe, noise = extract_orders(\n",
    "    ccd1_runs = calibration_runs['FibTh_180.0'][:1],\n",
    "    ccd2_runs = calibration_runs['FibTh_60.0'][:1],\n",
    "    ccd3_runs = calibration_runs['FibTh_15.0'][:1]\n",
    ")\n",
    "\n",
    "# Extract Master LC\n",
    "print('Extracting Master LC')\n",
    "master_lc, noise = extract_orders(\n",
    "    ccd1_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd2_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd3_runs = calibration_runs['SimLC'][-1:],\n",
    "    LC = True,\n",
    "    # tramline_debug = True\n",
    ")\n",
    "\n",
    "# Extract Science Objects\n",
    "for science_object in list(science_runs.keys()):\n",
    "    print('Extracting '+science_object)\n",
    "    try:\n",
    "        science, science_noise = extract_orders(\n",
    "            ccd1_runs = science_runs[science_object],\n",
    "            ccd2_runs = science_runs[science_object],\n",
    "            ccd3_runs = science_runs[science_object],\n",
    "            Science=True\n",
    "        )\n",
    "\n",
    "        # Create a primary HDU and HDU list\n",
    "        primary_hdu = fits.PrimaryHDU()\n",
    "        hdul = fits.HDUList([primary_hdu])\n",
    "\n",
    "        # Loop over your extension names and corresponding data arrays\n",
    "        for ext_index, ext_name in enumerate(initial_order_coeffs):\n",
    "            # Create an ImageHDU object for each extension\n",
    "            \n",
    "            # There is not ThXe available for CCD1's order 138.\n",
    "            if ext_name != 'ccd_1_order_138':\n",
    "\n",
    "                # Define the columns with appropriate formats\n",
    "                col1_def = fits.Column(name='wave_vac',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "                col2_def = fits.Column(name='wave_air',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "                col3_def = fits.Column(name='science', format='E', array=science[ext_index,:])\n",
    "                col4_def = fits.Column(name='science_noise',   format='E', array=science_noise[ext_index,:])\n",
    "                col5_def = fits.Column(name='flat',    format='E', array=master_flat[ext_index,:])\n",
    "                col6_def = fits.Column(name='thxe',    format='E', array=master_thxe[ext_index,:])\n",
    "                col7_def = fits.Column(name='lc',      format='E', array=master_lc[ext_index,:])\n",
    "\n",
    "                hdu = fits.BinTableHDU.from_columns([col1_def, col2_def, col3_def, col4_def, col5_def, col6_def, col7_def], name=science_object+'_'+ext_name.lower())\n",
    "\n",
    "                # Append the HDU to the HDU list\n",
    "                hdul.append(hdu)\n",
    "\n",
    "        # Save to a new FITS file with an extension for each order\n",
    "        Path(config.working_directory+'reduced_data/'+config.date+'/minimal_spectra/'+science_object).mkdir(parents=True, exist_ok=True)    \n",
    "        hdul.writeto(config.working_directory+'reduced_data/'+config.date+'/minimal_spectra/'+science_object+'/minimal_'+science_object+'.fits', overwrite=True)\n",
    "\n",
    "    except:\n",
    "        print('Failed to extract '+science_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e644ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
