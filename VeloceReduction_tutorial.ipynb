{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c53d78",
   "metadata": {},
   "source": [
    "# VeloceReduction -- Tutorial\n",
    "\n",
    "This tutorial provides an example on how to reduce data of a given night YYMMDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b08276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Basic packages\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VeloceReduction modules and function\n",
    "from VeloceReduction import config\n",
    "import VeloceReduction as VR\n",
    "\n",
    "from astropy.table import Table\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "from VeloceReduction.utils import polynomial_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982f57a",
   "metadata": {},
   "source": [
    "## Adjust Date and Directory (possibly via argument parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba063e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description=\"Process some inputs.\")\n",
    "    \n",
    "    # Add arguments\n",
    "    parser.add_argument('-d','--date', type=str, default=\"001122\",\n",
    "                        help='Date in the format DDMMYY (e.g., \"001122\")')\n",
    "    parser.add_argument('-wd','--working_directory', type=str, default=\"./\",\n",
    "                        help='The directory where the script will operate.')\n",
    "    \n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_script_input():\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        \n",
    "        # Assume default values if inside Jupyter\n",
    "        jupyter_date = \"001122\"\n",
    "        \n",
    "        # 2Amp example\n",
    "#         jupyter_date = \"240219\"\n",
    "        \n",
    "        # 4Amp example\n",
    "#         jupyter_date = \"231121\"\n",
    "        \n",
    "#         jupyter_date = \"240201\"\n",
    "        \n",
    "#         jupyter_date = \"240321\"\n",
    "        \n",
    "        jupyter_working_directory = \"./\"\n",
    "        print(\"Running in a Jupyter notebook. Using predefined values\")\n",
    "        args = argparse.Namespace(date=jupyter_date, working_directory=jupyter_working_directory)\n",
    "    else:\n",
    "        # Use argparse to handle command-line arguments\n",
    "        print(\"Running as a standalone Python script\")\n",
    "        args = parse_arguments()\n",
    "\n",
    "    return args\n",
    "\n",
    "# Use the function to get input\n",
    "args = get_script_input()\n",
    "config.date = args.date\n",
    "config.working_directory = args.working_directory\n",
    "print(f\"Date: {args.date}, Working Directory: {args.working_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4baf7e",
   "metadata": {},
   "source": [
    "## Identfiy Calibration and Science Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Calibration and Science data from the night log\n",
    "calibration_runs, science_runs = VR.utils.identify_calibration_and_science_runs(config.date, config.working_directory+'observations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ac5ac",
   "metadata": {},
   "source": [
    "## Extract orders and save in initial FITS files with an extension per order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract order ranges and coefficients\n",
    "order_ranges, order_beginning_coeffs, order_ending_coeffs = VR.extraction.read_in_order_tramlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cccdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract Master Flat\n",
    "print('Extracting Master Flat')\n",
    "master_flat, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['Flat_60.0'][:1],\n",
    "    ccd2_runs = calibration_runs['Flat_1.0'][:1],\n",
    "    ccd3_runs = calibration_runs['Flat_0.1'][:1],\n",
    "    Flat = True,\n",
    "    update_tramlines_based_on_flat = False, # Would update and overwrite\n",
    "    # ./VeloceReduction/tramline_information/tramline_begin_end_ccd_*_oder_*.txt\n",
    "    debug_overscan = False,\n",
    "    debug_tramlines = False # Would create a tramlines trace PDF under\n",
    "    # ./VeloceReduction/tramline_information/debug_tramlines_flat.pdf\n",
    ")\n",
    "\n",
    "# Extract Master ThXe\n",
    "print('Extracting Master ThXe')\n",
    "master_thxe, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['FibTh_180.0'][:1],\n",
    "    ccd2_runs = calibration_runs['FibTh_60.0'][:1],\n",
    "    ccd3_runs = calibration_runs['FibTh_15.0'][:1],\n",
    "    debug_tramlines = False # Would create a tramlines trace PDF under\n",
    "    # ./VeloceReduction/tramline_information/debug_tramlines.pdf\n",
    ")\n",
    "\n",
    "# Extract Master LC\n",
    "print('Extracting Master LC')\n",
    "master_lc, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd2_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd3_runs = calibration_runs['SimLC'][-1:],\n",
    "    LC = True,\n",
    "    debug_tramlines = False # Would create a tramlines trace PDF under\n",
    "    # ./VeloceReduction/tramline_information/debug_tramlines_lc.pdf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56105fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract Science Objects and save them into FITS files under reduced_data/\n",
    "for science_object in list(science_runs.keys())[1:2]:\n",
    "    print('Extracting '+science_object)\n",
    "    try:\n",
    "        science, science_noise, science_header = VR.extraction.extract_orders(\n",
    "            ccd1_runs = science_runs[science_object],\n",
    "            ccd2_runs = science_runs[science_object],\n",
    "            ccd3_runs = science_runs[science_object],\n",
    "            Science=True,\n",
    "            debug_tramlines = False, # Would create a tramlines trace PDF under\n",
    "            # ./VeloceReduction/tramline_information/debug_tramlines_science.pdf\n",
    "            debug_overscan=False\n",
    "        )\n",
    "\n",
    "        # Create a primary HDU and HDU list\n",
    "        primary_hdu = fits.PrimaryHDU()\n",
    "        header = primary_hdu.header\n",
    "        header['OBJECT']             = (science_header['OBJECT'], 'Name of observed object in night log')\n",
    "        header['HIERARCH SOURCE_ID'] = (-1,                       'Gaia DR3 source_id')\n",
    "        header['HIERARCH TMASS_ID']  = ('HHMMSSSS-DDMMSSS',       'Identifier in 2MASS catalog')\n",
    "        header['UTMJD']              = (science_header['UTMJD'],  'Modified Julian Date of observation')\n",
    "        header['MEANRA']             = (science_header['MEANRA'], 'Mean Right Ascension of observed object')\n",
    "        header['MEANDEC']            = (science_header['MEANDEC'],'Mean Declination of observed object')        \n",
    "        header['BARYVEL']            = ('None',                   'Applied barycentric velocity correction')\n",
    "        header['VRAD']               = ('None',                   'Radial velocity estimate')\n",
    "        header['E_VRAD']             = ('None',                   'Uncertainty of radial velocity estimate')\n",
    "        hdul = fits.HDUList([primary_hdu])\n",
    "\n",
    "        # Loop over your extension names and corresponding data arrays\n",
    "        for ext_index, ext_name in enumerate(order_beginning_coeffs):\n",
    "            # Create an ImageHDU object for each extension\n",
    "            \n",
    "            # Apply flat-field calibration to science\n",
    "            science[ext_index,:] /= master_flat[ext_index,:]\n",
    "            science_noise[ext_index,:] /= master_flat[ext_index,:]\n",
    "            \n",
    "            # Apply rough renormalisation with outlier-robuster 90th percenile of ~middle of order\n",
    "            science_90percentile = np.nanpercentile(science[ext_index,1500:2500],q=90)\n",
    "            science[ext_index,:] /= science_90percentile\n",
    "            science_noise[ext_index,:] /= science_90percentile\n",
    "            \n",
    "            # Define the columns with appropriate formats\n",
    "            col1_def = fits.Column(name='wave_vac',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "            col2_def = fits.Column(name='wave_air',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "            col3_def = fits.Column(name='science', format='E', array=science[ext_index,:])\n",
    "            col4_def = fits.Column(name='science_noise',   format='E', array=science_noise[ext_index,:])\n",
    "            col5_def = fits.Column(name='flat',    format='E', array=master_flat[ext_index,:])\n",
    "            col6_def = fits.Column(name='thxe',    format='E', array=master_thxe[ext_index,:]/master_flat[ext_index,:])\n",
    "            col7_def = fits.Column(name='lc',      format='E', array=master_lc[ext_index,:]/master_flat[ext_index,:])\n",
    "\n",
    "            # Combine columns to BinTable and add header from primary\n",
    "            hdu = fits.BinTableHDU.from_columns([col1_def, col2_def, col3_def, col4_def, col5_def, col6_def, col7_def], name=ext_name.lower())\n",
    "            hdu.header.extend(header.copy(strip=True), unique=True)\n",
    "            \n",
    "            # Append the HDU to the HDU list\n",
    "            hdul.append(hdu)\n",
    "\n",
    "        # Save to a new FITS file with an extension for each order\n",
    "        Path(config.working_directory+'reduced_data/'+config.date+'/'+science_object).mkdir(parents=True, exist_ok=True)\n",
    "        spectrum_filename = 'veloce_spectra_'+science_object+'_'+config.date+'.fits'\n",
    "        hdul.writeto(config.working_directory+'reduced_data/'+config.date+'/'+science_object+'/'+spectrum_filename, overwrite=True)\n",
    "\n",
    "        print('  -> Successfully extracted '+science_object)\n",
    "\n",
    "    except:\n",
    "        print('  -> Failed to extract '+science_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a7445",
   "metadata": {},
   "source": [
    "## Wavelength calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b6d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for science_object in list(science_runs.keys()):\n",
    "    try:\n",
    "        VR.calibration.calibrate_wavelength(\n",
    "            science_object,\n",
    "            optimise_lc_solution=False,\n",
    "            correct_barycentric_velocity=True,\n",
    "            create_overview_pdf=True\n",
    "        )\n",
    "        print('  -> Succesfully calibrated wavelength with diagnostic plots for '+science_object)\n",
    "    except:\n",
    "        print('  -> Failed to calibrate wavelength for '+science_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
