{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c53d78",
   "metadata": {},
   "source": [
    "# VeloceReduction -- Tutorial\n",
    "\n",
    "This tutorial provides an example on how to reduce data of a given night YYMMDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b08276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Basic packages\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VeloceReduction modules and function\n",
    "from VeloceReduction import config\n",
    "import VeloceReduction as VR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982f57a",
   "metadata": {},
   "source": [
    "## Adjust Date and Directory (possibly via argument parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba063e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description=\"Process some inputs.\")\n",
    "    \n",
    "    # Add arguments\n",
    "    parser.add_argument('-d','--date', type=str, default=\"001122\",\n",
    "                        help='Date in the format DDMMYY (e.g., \"001122\")')\n",
    "    parser.add_argument('-wd','--working_directory', type=str, default=\"./\",\n",
    "                        help='The directory where the script will operate.')\n",
    "    \n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_script_input():\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        \n",
    "        # Assume default values if inside Jupyter\n",
    "        jupyter_date = \"001122\"\n",
    "        \n",
    "        # 2Amp example\n",
    "        #jupyter_date = \"240219\"\n",
    "        \n",
    "        # 4Amp example\n",
    "        # jupyter_date = \"231121\"\n",
    "        \n",
    "        jupyter_working_directory = \"./\"\n",
    "        print(\"Running in a Jupyter notebook. Using predefined values\")\n",
    "        args = argparse.Namespace(date=jupyter_date, working_directory=jupyter_working_directory)\n",
    "    else:\n",
    "        # Use argparse to handle command-line arguments\n",
    "        print(\"Running as a standalone Python script\")\n",
    "        args = parse_arguments()\n",
    "\n",
    "    return args\n",
    "\n",
    "# Use the function to get input\n",
    "args = get_script_input()\n",
    "config.date = args.date\n",
    "config.working_directory = args.working_directory\n",
    "print(f\"Date: {args.date}, Working Directory: {args.working_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4baf7e",
   "metadata": {},
   "source": [
    "## Identfiy Calibration and Science Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Calibration and Science data from the night log\n",
    "calibration_runs, science_runs = VR.utils.identify_calibration_and_science_runs(config.date, config.working_directory+'observations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ac5ac",
   "metadata": {},
   "source": [
    "## Extract orders and save in initial FITS files with an extension per order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract initial order ranges and coefficients\n",
    "initial_order_ranges, initial_order_coeffs = VR.extraction.extract_initial_order_ranges_and_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cccdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract Master Flat\n",
    "print('Extracting Master Flat')\n",
    "master_flat, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['Flat_60.0'][:1],\n",
    "    ccd2_runs = calibration_runs['Flat_1.0'][:1],\n",
    "    ccd3_runs = calibration_runs['Flat_0.1'][:1],\n",
    "    Flat = True,\n",
    "    #debug_overscan=True\n",
    ")\n",
    "\n",
    "# Extract Master ThXe\n",
    "print('Extracting Master ThXe')\n",
    "master_thxe, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['FibTh_180.0'][:1],\n",
    "    ccd2_runs = calibration_runs['FibTh_60.0'][:1],\n",
    "    ccd3_runs = calibration_runs['FibTh_15.0'][:1]\n",
    ")\n",
    "\n",
    "# Extract Master LC\n",
    "print('Extracting Master LC')\n",
    "master_lc, noise = VR.extraction.extract_orders(\n",
    "    ccd1_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd2_runs = calibration_runs['SimLC'][-1:],\n",
    "    ccd3_runs = calibration_runs['SimLC'][-1:],\n",
    "    LC = True,\n",
    "    # tramline_debug = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56105fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract Science Objects and save them into FITS files under reduced_data/\n",
    "for science_object in list(science_runs.keys()):\n",
    "    print('Extracting '+science_object)\n",
    "    try:\n",
    "        science, science_noise, science_header = VR.extraction.extract_orders(\n",
    "            ccd1_runs = science_runs[science_object],\n",
    "            ccd2_runs = science_runs[science_object],\n",
    "            ccd3_runs = science_runs[science_object],\n",
    "            Science=True,\n",
    "            #debug_overscan=True\n",
    "        )\n",
    "\n",
    "        # Create a primary HDU and HDU list\n",
    "        primary_hdu = fits.PrimaryHDU()\n",
    "        header = primary_hdu.header\n",
    "        header['OBJECT']  = (science_header['OBJECT'], 'Name of observed object in night log')\n",
    "        header['UTMJD']   = (science_header['UTMJD'],  'Modified Julian Date of observation')\n",
    "        header['MEANRA']  = (science_header['MEANRA'], 'Mean Right Ascension of observed object')\n",
    "        header['MEANDEC'] = (science_header['MEANDEC'],'Mean Declination of observed object')        \n",
    "        header['BARYVEL'] = ('None',                   'Applied barycentric velocity correction')\n",
    "        hdul = fits.HDUList([primary_hdu])\n",
    "\n",
    "        # Loop over your extension names and corresponding data arrays\n",
    "        for ext_index, ext_name in enumerate(initial_order_coeffs):\n",
    "            # Create an ImageHDU object for each extension\n",
    "\n",
    "            # Define the columns with appropriate formats\n",
    "            col1_def = fits.Column(name='wave_vac',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "            col2_def = fits.Column(name='wave_air',format='E', array=np.arange(len(science[ext_index,:]),dtype=float))\n",
    "            col3_def = fits.Column(name='science', format='E', array=science[ext_index,:]/master_flat[ext_index,:])\n",
    "            col4_def = fits.Column(name='science_noise',   format='E', array=science_noise[ext_index,:]/master_flat[ext_index,:])\n",
    "            col5_def = fits.Column(name='flat',    format='E', array=master_flat[ext_index,:])\n",
    "            col6_def = fits.Column(name='thxe',    format='E', array=master_thxe[ext_index,:]/master_flat[ext_index,:])\n",
    "            col7_def = fits.Column(name='lc',      format='E', array=master_lc[ext_index,:]/master_flat[ext_index,:])\n",
    "\n",
    "            hdu = fits.BinTableHDU.from_columns([col1_def, col2_def, col3_def, col4_def, col5_def, col6_def, col7_def], name=ext_name.lower())\n",
    "\n",
    "            # Append the HDU to the HDU list\n",
    "            hdul.append(hdu)\n",
    "\n",
    "        # Save to a new FITS file with an extension for each order\n",
    "        Path(config.working_directory+'reduced_data/'+config.date+'/'+science_object).mkdir(parents=True, exist_ok=True)\n",
    "        spectrum_filename = 'veloce_spectra_'+science_object+'_'+config.date+'.fits'\n",
    "        hdul.writeto(config.working_directory+'reduced_data/'+config.date+'/'+science_object+'/'+spectrum_filename, overwrite=True)\n",
    "\n",
    "        print('  -> Successfully extracted '+science_object)\n",
    "\n",
    "    except:\n",
    "        print('  -> Failed to extract '+science_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a7445",
   "metadata": {},
   "source": [
    "## Wavelength calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907d4cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for science_object in list(science_runs.keys()):\n",
    "#     try:\n",
    "    VR.calibration.calibrate_wavelength(science_object, correct_barycentric_velocity=True, create_overview_pdf=False)\n",
    "    print('  -> Succesfully calibrated wavelength without diagnostic plots for '+science_object)\n",
    "#     except:\n",
    "#         print('  -> Failed to calibrate wavelength for '+science_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b6d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for science_object in list(science_runs.keys()):\n",
    "#     try:\n",
    "    VR.calibration.calibrate_wavelength(science_object, correct_barycentric_velocity=True, create_overview_pdf=True)\n",
    "    print('  -> Succesfully calibrated wavelength with diagnostic plots for '+science_object)\n",
    "#     except:\n",
    "#         print('  -> Failed to calibrate wavelength for '+science_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428deeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
